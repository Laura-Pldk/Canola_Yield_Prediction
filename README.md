# Statistical Consulting Project: Explainable AI for Time Series Forecasting 

In the current data-rich landscape, businesses are exponentially turning to time series forecasting for informed decisions. For every decision-making process transparency, trust and confidence in the model is very important. Users need to understand and trust the model outcomes. Our aim is to delve deeply into the realm of Explainable AI for time series forecasting, while emphasizing uncertainty quantification for feature importance and predictions. We intend to analyze various scenarios using different approaches to generate valuable insights for users. Starting with an exploration of XAI in itself, focusing on techniques and tools specifically for time series forecasting. As part of our practical study, we will be comparing them against transparent and understandable reference approaches. As part of the literature review, methods such as those among the following will be explored:

## Methods

- SHAP (SHapley Additive exPlanations) to understand the contribution of each feature to individual predictions.

- LIME (Local Interpretable Model-agnostic Explanations) to locally approximate complex models with simpler interpretable models. 

- Feature Importance Uncertainty Quantification techniques to measure uncertainty of the feature importance and predictions.
