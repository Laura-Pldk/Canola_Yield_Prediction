{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import glob\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataframe \n",
    "canola_2 = df = pd.read_csv('../data/rm-yields-data.csv', header=0, index_col=0, parse_dates=True)\n",
    "canola_small = canola_2.iloc[:, [0, 2]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "#read dataframe \n",
    "canola_2 = df = pd.read_csv('../data/rm-yields-data.csv', header=0, index_col=0, parse_dates=True)\n",
    "canola_small = canola_2.iloc[:, [0, 2]].copy()\n",
    "\n",
    "start_year = 1938\n",
    "start_analysis = 1990\n",
    "exclude_years = start_analysis - start_year\n",
    "#cut 70s and 80s as well \n",
    "#cut of first 52 observations (NAs)\n",
    "canola_small.drop(canola_small.index[:exclude_years], inplace=True)\n",
    "\n",
    "#filter out every observation that contains NAs\n",
    "canola_filtered = canola_small.groupby('RM').filter(lambda group: not group['Canola'].isnull().any())\n",
    "\n",
    "# how may districts? 148\n",
    "num_districts = canola_filtered.groupby('RM').ngroups\n",
    "print(num_districts)\n",
    "#excluding 70s and 80s lead to 36 more colmplete districts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'RM' and check if 'Canola' has any missing values in each group\n",
    "districts_with_full_data = canola_filtered.groupby('RM')['Canola'].apply(lambda group: not group.isnull().any())\n",
    "\n",
    "# Extract the list of districts with full data\n",
    "districts_with_full_data_list = districts_with_full_data[districts_with_full_data].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select weather data\n",
    "#open only the years from 1990 til 2022\n",
    "\n",
    "# Define the directory path and pattern for the NetCDF files\n",
    "directory_path = '../data/all_raw_data/'\n",
    "file_pattern = 'data_*.nc'\n",
    "\n",
    "# Get a list of files matching the pattern\n",
    "files_to_open = glob.glob(os.path.join(directory_path, file_pattern))\n",
    "\n",
    "# Open only the files for the years 1990 to 2022\n",
    "years_to_open = list(map(str, range(start_analysis, 2023)))\n",
    "files_to_open = [file for file in files_to_open if any(year in file for year in years_to_open)]\n",
    "\n",
    "# Use open_mfdataset to open the selected files\n",
    "cop_all_90 = xr.open_mfdataset(files_to_open, combine='by_coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center points for regions\n",
    "df_regions = pd.read_csv(r'../data/cgn_sk_csv_eng.csv')\n",
    "df_rms = df_regions[['Geographical Name','Latitude', 'Longitude']][df_regions['Generic Term'] == 'Rural Municipality']\n",
    "df_rms['region_index'] = df_rms['Geographical Name'].str.split(' ').str[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center(region):\n",
    "    avg_lat = df_rms['Latitude'][df_rms['region_index'] == region].item()\n",
    "    avg_long = df_rms['Longitude'][df_rms['region_index'] == region].item()\n",
    "    return avg_lat, avg_long\n",
    "\n",
    "def detrend_ts(df_region):\n",
    "    # linear detrending\n",
    "    forecaster = PolynomialTrendForecaster(degree=2)\n",
    "    transformer = Detrender(forecaster=forecaster)\n",
    "    yt = transformer.fit_transform(df_region['Canola'])\n",
    "    return yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_canola_weather_data(region = 310):\n",
    "    # select data from region with center point\n",
    "    center_lat, center_long = get_center(region)\n",
    "    cropped_data_tmp = cop_all_90.sel(longitude=center_long, latitude=center_lat,method='nearest')\n",
    "\n",
    "    # get residuals for canola yield\n",
    "    df_tmp = canola_filtered[canola_filtered['RM'] == region]\n",
    "    residuals = detrend_ts(df_tmp)\n",
    "\n",
    "    # merge weather data and canola residuals\n",
    "    df_weather_region = cropped_data_tmp.to_dataframe()\n",
    "\n",
    "    df_weather_region['region'] = region\n",
    "\n",
    "    column_to_append = residuals.tolist()\n",
    "    years = df_weather_region.index.year\n",
    "    df_weather_region['Canola_detrended'] = [column_to_append[year - start_analysis] for year in years]\n",
    "    df_weather_region.drop(['longitude','latitude'],axis=1,inplace=True)\n",
    "\n",
    "    return df_weather_region, pd.DataFrame(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_temp_features(df_weather_region, df_year):\n",
    "    for month in range(4,11):    \n",
    "        daily_max_temperatures = df_weather_region.resample('D').max()\n",
    "        monthly_avg_max_temperatures = daily_max_temperatures.resample('MS').mean()\n",
    "        \n",
    "    #     dist1_df_month = dist1_df.resample('MS').mean()\n",
    "        month_data = monthly_avg_max_temperatures[monthly_avg_max_temperatures.index.month == month]\n",
    "        column_to_append = month_data['t2m'].tolist()\n",
    "        df_year.loc[:, f'average_max_temp_in_{month}'] = column_to_append\n",
    "    return df_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_regions = [region for region in districts_with_full_data_list if region in df_rms['region_index'].to_list()]\n",
    "len(available_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_regions.remove(278) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Need at least 3 dates to infer frequency",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m dfs_of_years \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m region \u001b[38;5;129;01min\u001b[39;00m available_regions:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#print(region)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     df_weather_region, df_year \u001b[38;5;241m=\u001b[39m merge_canola_weather_data(region)\n\u001b[0;32m      5\u001b[0m     df_year\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df_year\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear\n\u001b[0;32m      6\u001b[0m     df_year[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m region\n",
      "Cell \u001b[1;32mIn[108], line 8\u001b[0m, in \u001b[0;36mmerge_canola_weather_data\u001b[1;34m(region)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# get residuals for canola yield\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df_tmp \u001b[38;5;241m=\u001b[39m canola_filtered[canola_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m region]\n\u001b[1;32m----> 8\u001b[0m residuals \u001b[38;5;241m=\u001b[39m detrend_ts(df_tmp)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# merge weather data and canola residuals\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df_weather_region \u001b[38;5;241m=\u001b[39m cropped_data_tmp\u001b[38;5;241m.\u001b[39mto_dataframe()\n",
      "Cell \u001b[1;32mIn[107], line 10\u001b[0m, in \u001b[0;36mdetrend_ts\u001b[1;34m(df_region)\u001b[0m\n\u001b[0;32m      8\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m PolynomialTrendForecaster(degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      9\u001b[0m transformer \u001b[38;5;241m=\u001b[39m Detrender(forecaster\u001b[38;5;241m=\u001b[39mforecaster)\n\u001b[1;32m---> 10\u001b[0m yt \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(df_region[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanola\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m yt\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sktime\\transformations\\base.py:669\u001b[0m, in \u001b[0;36mBaseTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit to data, then transform it.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03mFits the transformer to X and y and returns a transformed version of X.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m        Example: i-th instance of the output is the i-th window running over `X`\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m# Non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# method is possible for a given algorithm.\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y)\u001b[38;5;241m.\u001b[39mtransform(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sktime\\transformations\\base.py:486\u001b[0m, in \u001b[0;36mBaseTransformer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# we call the ordinary _fit if no looping/vectorization needed\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vectorization_needed:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X\u001b[38;5;241m=\u001b[39mX_inner, y\u001b[38;5;241m=\u001b[39my_inner)\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of fit\u001b[39;00m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m=\u001b[39mX_inner, y\u001b[38;5;241m=\u001b[39my_inner)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sktime\\transformations\\series\\detrend\\_detrend.py:119\u001b[0m, in \u001b[0;36mDetrender._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit transformer to X and y.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03mprivate _fit containing the core logic, called from fit\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mself: a fitted instance of the estimator\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecaster_\u001b[38;5;241m.\u001b[39mget_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires-fh-in-fit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecaster_\u001b[38;5;241m.\u001b[39mfit(y\u001b[38;5;241m=\u001b[39mX, X\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X \u001b[38;5;241m=\u001b[39m X\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:372\u001b[0m, in \u001b[0;36mBaseForecaster.fit\u001b[1;34m(self, y, X, fh)\u001b[0m\n\u001b[0;32m    368\u001b[0m X_inner, y_inner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# set internal X/y to the new X/y\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# this also updates cutoff from y\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_y_X(y_inner, X_inner)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# check forecasting horizon and coerce to ForecastingHorizon object\u001b[39;00m\n\u001b[0;32m    375\u001b[0m fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fh(fh)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:1579\u001b[0m, in \u001b[0;36mBaseForecaster._update_y_X\u001b[1;34m(self, y, X, enforce_index_type)\u001b[0m\n\u001b[0;32m   1576\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y \u001b[38;5;241m=\u001b[39m update_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y, y)\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;66;03m# set cutoff to the end of the observation horizon\u001b[39;00m\n\u001b[1;32m-> 1579\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_cutoff_from_y(y)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;66;03m# unwrap X if VectorizedDF\u001b[39;00m\n\u001b[0;32m   1583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, VectorizedDF):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:1634\u001b[0m, in \u001b[0;36mBaseForecaster._set_cutoff_from_y\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m   1620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_cutoff_from_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set and update cutoff from series y.\u001b[39;00m\n\u001b[0;32m   1622\u001b[0m \n\u001b[0;32m   1623\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;124;03m    Set self._cutoff to pandas.Index containing latest index seen in `y`.\u001b[39;00m\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1634\u001b[0m     cutoff_idx \u001b[38;5;241m=\u001b[39m get_cutoff(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcutoff, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cutoff \u001b[38;5;241m=\u001b[39m cutoff_idx\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sktime\\datatypes\\_utilities.py:287\u001b[0m, in \u001b[0;36mget_cutoff\u001b[1;34m(obj, cutoff, return_index, reverse_order, check_input, convert_input)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pd\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sub_idx(obj\u001b[38;5;241m.\u001b[39mindex, ix, return_index)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# nested_univ (Panel) or pd.DataFrame(Series)\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mindex, pd\u001b[38;5;241m.\u001b[39mMultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sktime\\datatypes\\_utilities.py:280\u001b[0m, in \u001b[0;36mget_cutoff.<locals>.sub_idx\u001b[1;34m(idx, ix, return_index)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfreq\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m         res\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39minfer_freq(idx)\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mfreq \u001b[38;5;241m!=\u001b[39m idx\u001b[38;5;241m.\u001b[39mfreq:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\tseries\\frequencies.py:174\u001b[0m, in \u001b[0;36minfer_freq\u001b[1;34m(index)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, DatetimeIndex):\n\u001b[0;32m    172\u001b[0m     index \u001b[38;5;241m=\u001b[39m DatetimeIndex(index)\n\u001b[1;32m--> 174\u001b[0m inferer \u001b[38;5;241m=\u001b[39m _FrequencyInferer(index)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferer\u001b[38;5;241m.\u001b[39mget_freq()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\tseries\\frequencies.py:208\u001b[0m, in \u001b[0;36m_FrequencyInferer.__init__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi8values \u001b[38;5;241m=\u001b[39m tz_convert_from_utc(\n\u001b[0;32m    204\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi8values, index\u001b[38;5;241m.\u001b[39mtz, reso\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_creso\n\u001b[0;32m    205\u001b[0m         )\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed at least 3 dates to infer frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_monotonic \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_is_monotonic_increasing \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_is_monotonic_decreasing\n\u001b[0;32m    212\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Need at least 3 dates to infer frequency"
     ]
    }
   ],
   "source": [
    "dfs_of_years = []\n",
    "for region in available_regions:\n",
    "    #print(region)\n",
    "    df_weather_region, df_year = merge_canola_weather_data(region)\n",
    "    df_year.index = df_year.index.year\n",
    "    df_year['region'] = region\n",
    "    df_year = calc_temp_features(df_weather_region,df_year)\n",
    "    dfs_of_years.append(df_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m region \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m278\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#for region in available_regions:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#print(region)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df_weather_region, df_year \u001b[38;5;241m=\u001b[39m merge_canola_weather_data(region)\n\u001b[0;32m      7\u001b[0m df_year\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df_year\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear\n\u001b[0;32m      8\u001b[0m df_year[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m region\n",
      "Cell \u001b[1;32mIn[68], line 17\u001b[0m, in \u001b[0;36mmerge_canola_weather_data\u001b[1;34m(region)\u001b[0m\n\u001b[0;32m     15\u001b[0m column_to_append \u001b[38;5;241m=\u001b[39m residuals\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     16\u001b[0m years \u001b[38;5;241m=\u001b[39m df_weather_region\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m---> 17\u001b[0m df_weather_region[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanola_detrended\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [column_to_append[year \u001b[38;5;241m-\u001b[39m start_analysis] \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years]\n\u001b[0;32m     18\u001b[0m df_weather_region\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_weather_region, pd\u001b[38;5;241m.\u001b[39mDataFrame(residuals)\n",
      "Cell \u001b[1;32mIn[68], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     15\u001b[0m column_to_append \u001b[38;5;241m=\u001b[39m residuals\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     16\u001b[0m years \u001b[38;5;241m=\u001b[39m df_weather_region\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m---> 17\u001b[0m df_weather_region[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanola_detrended\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [column_to_append[year \u001b[38;5;241m-\u001b[39m start_analysis] \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years]\n\u001b[0;32m     18\u001b[0m df_weather_region\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_weather_region, pd\u001b[38;5;241m.\u001b[39mDataFrame(residuals)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dfs_of_years = []\n",
    "\n",
    "region = 278\n",
    "#for region in available_regions:\n",
    "#print(region)\n",
    "df_weather_region, df_year = merge_canola_weather_data(region)\n",
    "df_year.index = df_year.index.year\n",
    "df_year['region'] = region\n",
    "df_year = calc_temp_features(df_weather_region,df_year)\n",
    "dfs_of_years.append(df_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 61,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 95,\n",
       " 96,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 131,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 181,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 189,\n",
       " 190,\n",
       " 194,\n",
       " 211,\n",
       " 213,\n",
       " 214,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 241,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 271,\n",
       " 273,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 288,\n",
       " 304,\n",
       " 305,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 320,\n",
       " 331,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 394,\n",
       " 395,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 442,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 463,\n",
       " 464,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 471,\n",
       " 472,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 490,\n",
       " 491,\n",
       " 493,\n",
       " 494,\n",
       " 497,\n",
       " 499,\n",
       " 501,\n",
       " 502,\n",
       " 520,\n",
       " 529,\n",
       " 588,\n",
       " 622]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat(dfs_of_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "df_full\n",
    "\n",
    "unique_region_count = df_full['region'].nunique()\n",
    "print(unique_region_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maris\\AppData\\Local\\Temp\\ipykernel_15648\\4228704258.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1990.rename(columns={'region': 'region_index'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canola</th>\n",
       "      <th>region_index</th>\n",
       "      <th>average_max_temp_in_4</th>\n",
       "      <th>average_max_temp_in_5</th>\n",
       "      <th>average_max_temp_in_6</th>\n",
       "      <th>average_max_temp_in_7</th>\n",
       "      <th>average_max_temp_in_8</th>\n",
       "      <th>average_max_temp_in_9</th>\n",
       "      <th>average_max_temp_in_10</th>\n",
       "      <th>Geographical Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127132</td>\n",
       "      <td>1</td>\n",
       "      <td>284.965759</td>\n",
       "      <td>290.526489</td>\n",
       "      <td>297.082458</td>\n",
       "      <td>299.412781</td>\n",
       "      <td>300.752075</td>\n",
       "      <td>296.791382</td>\n",
       "      <td>286.036377</td>\n",
       "      <td>Argyle No. 1</td>\n",
       "      <td>49.154052</td>\n",
       "      <td>-101.479393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.250299</td>\n",
       "      <td>2</td>\n",
       "      <td>285.097748</td>\n",
       "      <td>290.557587</td>\n",
       "      <td>296.971375</td>\n",
       "      <td>299.475037</td>\n",
       "      <td>300.810242</td>\n",
       "      <td>296.785919</td>\n",
       "      <td>286.065613</td>\n",
       "      <td>Mount Pleasant No. 2</td>\n",
       "      <td>49.134400</td>\n",
       "      <td>-101.814863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.254749</td>\n",
       "      <td>3</td>\n",
       "      <td>284.934357</td>\n",
       "      <td>290.402344</td>\n",
       "      <td>296.612885</td>\n",
       "      <td>299.007629</td>\n",
       "      <td>300.521759</td>\n",
       "      <td>296.678101</td>\n",
       "      <td>285.860657</td>\n",
       "      <td>Enniskillen No. 3</td>\n",
       "      <td>49.162144</td>\n",
       "      <td>-102.206941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.237970</td>\n",
       "      <td>31</td>\n",
       "      <td>284.553070</td>\n",
       "      <td>290.128845</td>\n",
       "      <td>296.719269</td>\n",
       "      <td>298.715149</td>\n",
       "      <td>300.327728</td>\n",
       "      <td>296.484863</td>\n",
       "      <td>285.571869</td>\n",
       "      <td>Storthoaks No. 31</td>\n",
       "      <td>49.421968</td>\n",
       "      <td>-101.535339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.365171</td>\n",
       "      <td>32</td>\n",
       "      <td>284.487640</td>\n",
       "      <td>290.010986</td>\n",
       "      <td>296.416443</td>\n",
       "      <td>298.459534</td>\n",
       "      <td>300.064056</td>\n",
       "      <td>296.286194</td>\n",
       "      <td>285.277344</td>\n",
       "      <td>Reciprocity No. 32</td>\n",
       "      <td>49.412910</td>\n",
       "      <td>-101.873375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>8.047634</td>\n",
       "      <td>497</td>\n",
       "      <td>283.672668</td>\n",
       "      <td>289.998840</td>\n",
       "      <td>295.684509</td>\n",
       "      <td>295.920105</td>\n",
       "      <td>296.795441</td>\n",
       "      <td>293.605438</td>\n",
       "      <td>280.930847</td>\n",
       "      <td>Medstead No. 497</td>\n",
       "      <td>53.437744</td>\n",
       "      <td>-108.121150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.579032</td>\n",
       "      <td>499</td>\n",
       "      <td>284.496735</td>\n",
       "      <td>290.571686</td>\n",
       "      <td>296.169250</td>\n",
       "      <td>296.506378</td>\n",
       "      <td>297.331329</td>\n",
       "      <td>294.314758</td>\n",
       "      <td>281.821869</td>\n",
       "      <td>Mervin No. 499</td>\n",
       "      <td>53.507469</td>\n",
       "      <td>-108.820647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>5.553036</td>\n",
       "      <td>501</td>\n",
       "      <td>284.257782</td>\n",
       "      <td>290.010315</td>\n",
       "      <td>295.045013</td>\n",
       "      <td>296.041473</td>\n",
       "      <td>296.657806</td>\n",
       "      <td>293.918488</td>\n",
       "      <td>281.664215</td>\n",
       "      <td>Frenchman Butte No. 501</td>\n",
       "      <td>53.584865</td>\n",
       "      <td>-109.647239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>9.416794</td>\n",
       "      <td>502</td>\n",
       "      <td>284.265106</td>\n",
       "      <td>290.014374</td>\n",
       "      <td>294.966156</td>\n",
       "      <td>296.034210</td>\n",
       "      <td>296.618378</td>\n",
       "      <td>293.906158</td>\n",
       "      <td>281.671234</td>\n",
       "      <td>Britannia No. 502</td>\n",
       "      <td>53.504863</td>\n",
       "      <td>-109.697586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.616702</td>\n",
       "      <td>520</td>\n",
       "      <td>282.834991</td>\n",
       "      <td>289.790619</td>\n",
       "      <td>296.638824</td>\n",
       "      <td>295.890350</td>\n",
       "      <td>297.039001</td>\n",
       "      <td>293.938141</td>\n",
       "      <td>280.586456</td>\n",
       "      <td>Paddockwood No. 520</td>\n",
       "      <td>53.733730</td>\n",
       "      <td>-105.452461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Canola  region_index  average_max_temp_in_4  average_max_temp_in_5  \\\n",
       "0    0.127132             1             284.965759             290.526489   \n",
       "1   -4.250299             2             285.097748             290.557587   \n",
       "2   -4.254749             3             284.934357             290.402344   \n",
       "3   -3.237970            31             284.553070             290.128845   \n",
       "4   -0.365171            32             284.487640             290.010986   \n",
       "..        ...           ...                    ...                    ...   \n",
       "174  8.047634           497             283.672668             289.998840   \n",
       "175 -0.579032           499             284.496735             290.571686   \n",
       "176  5.553036           501             284.257782             290.010315   \n",
       "177  9.416794           502             284.265106             290.014374   \n",
       "178  0.616702           520             282.834991             289.790619   \n",
       "\n",
       "     average_max_temp_in_6  average_max_temp_in_7  average_max_temp_in_8  \\\n",
       "0               297.082458             299.412781             300.752075   \n",
       "1               296.971375             299.475037             300.810242   \n",
       "2               296.612885             299.007629             300.521759   \n",
       "3               296.719269             298.715149             300.327728   \n",
       "4               296.416443             298.459534             300.064056   \n",
       "..                     ...                    ...                    ...   \n",
       "174             295.684509             295.920105             296.795441   \n",
       "175             296.169250             296.506378             297.331329   \n",
       "176             295.045013             296.041473             296.657806   \n",
       "177             294.966156             296.034210             296.618378   \n",
       "178             296.638824             295.890350             297.039001   \n",
       "\n",
       "     average_max_temp_in_9  average_max_temp_in_10        Geographical Name  \\\n",
       "0               296.791382              286.036377             Argyle No. 1   \n",
       "1               296.785919              286.065613     Mount Pleasant No. 2   \n",
       "2               296.678101              285.860657        Enniskillen No. 3   \n",
       "3               296.484863              285.571869        Storthoaks No. 31   \n",
       "4               296.286194              285.277344       Reciprocity No. 32   \n",
       "..                     ...                     ...                      ...   \n",
       "174             293.605438              280.930847         Medstead No. 497   \n",
       "175             294.314758              281.821869           Mervin No. 499   \n",
       "176             293.918488              281.664215  Frenchman Butte No. 501   \n",
       "177             293.906158              281.671234        Britannia No. 502   \n",
       "178             293.938141              280.586456      Paddockwood No. 520   \n",
       "\n",
       "      Latitude   Longitude  \n",
       "0    49.154052 -101.479393  \n",
       "1    49.134400 -101.814863  \n",
       "2    49.162144 -102.206941  \n",
       "3    49.421968 -101.535339  \n",
       "4    49.412910 -101.873375  \n",
       "..         ...         ...  \n",
       "174  53.437744 -108.121150  \n",
       "175  53.507469 -108.820647  \n",
       "176  53.584865 -109.647239  \n",
       "177  53.504863 -109.697586  \n",
       "178  53.733730 -105.452461  \n",
       "\n",
       "[179 rows x 12 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1990 = df_full.loc[1990]\n",
    "\n",
    "df_1990.rename(columns={'region': 'region_index'}, inplace=True)\n",
    "\n",
    "df_1990_coord = pd.merge(df_1990, df_rms, on='region_index')\n",
    "\n",
    "df_1990_coord\n",
    "#df_1990_coord.to_csv('C:/Users/maris/python_notebooks/XAI_TS_Forecasting/data/df_1990_coord.csv', sep=',', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
