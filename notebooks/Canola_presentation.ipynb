{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8eeb7d9",
   "metadata": {},
   "source": [
    "# Current State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5bb68a",
   "metadata": {},
   "source": [
    "## Domain Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae941a53",
   "metadata": {},
   "source": [
    "- Canola life cycle: May (seeding), late June - early July (bolting, flowering), July (peak flowering), mid August - early September (swathing), September (harvest)\n",
    "\n",
    "- minimum growth temp.: -5 degrees celsius (~268 degrees Kelvin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8caf1dd",
   "metadata": {},
   "source": [
    "## Hypothesis Propositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a857ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I. High temperatures (low precipitation) have a negative impact on Canola yield in Saskatchewan.\n",
    "## avg. temp in growing season, cum. heat days, heatwaves (X consecutive days above threshold), heat stress index\n",
    "\n",
    "# II. Greater-than-average precipitation has a positive impact on Canola yield in Saskatchewan.\n",
    "## heavy tp frequency\n",
    "\n",
    "# III. Cooler-than-average nocturnal temperatures have a positive impact on Canola yield in Saskatchewan.\n",
    "## avg nocturnal temperature\n",
    "\n",
    "# IV. The beginning of July, i.e. the early flowering period, is the critical time period for the effects in (I).\n",
    "\n",
    "# V. The critical threshold for temperature-caused yield loss is 30 degrees celsius.\n",
    "\n",
    "# VI. Increased precipitation may offset the negative impact of high temperatures on floweing canola.\n",
    "\n",
    "# VII. Canola crop yield increases (decreases) with increasing average temperatures in June and August (in July).\n",
    "\n",
    "# VIII. The crucial time for high precipitation benefits is the month of July, i.e. peak flowering season."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf929c",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce04f9b",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b62191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8986e",
   "metadata": {},
   "source": [
    "## Data Preparations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92459bf4",
   "metadata": {},
   "source": [
    "### Canola yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7553a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataframe \n",
    "canola_2 = df = pd.read_csv('../data/rm-yields-data.csv', header=0, index_col=0, parse_dates=True)\n",
    "canola_small = canola_2.iloc[:, [0, 2]].copy()\n",
    "\n",
    "#cut of first 33 observations (NAs)\n",
    "canola_small.drop(canola_small.index[:33], inplace=True)\n",
    "\n",
    "#filter out every observation that contains NAs\n",
    "canola_filtered = canola_small.groupby('RM').filter(lambda group: not group['Canola'].isnull().any())\n",
    "\n",
    "# how may districts? 148\n",
    "num_districts = canola_filtered.groupby('RM').ngroups\n",
    "\n",
    "#extract only the first district \n",
    "canola_dist1 = canola_filtered[canola_filtered['RM'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(canola_filtered)\n",
    "\n",
    "df_reset = canola_filtered.reset_index()\n",
    "#print(df_reset)\n",
    "# Pivot the DataFrame\n",
    "pivot_df = df_reset.pivot(index='Year', columns='RM', values='Canola')\n",
    "\n",
    "#print(pivot_df)\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = pivot_df.corr()\n",
    "correlation_matrix\n",
    "# Display or use the correlation matrix\n",
    "#print(correlation_matrix)\n",
    "\n",
    "selected_columns = pivot_df.columns[:20]  \n",
    "correlation_matrix_subset = pivot_df[selected_columns].corr()\n",
    "sns.heatmap(correlation_matrix_subset, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'RM' and check if 'Canola' has any missing values in each group\n",
    "districts_with_full_data = canola_filtered.groupby('RM')['Canola'].apply(lambda group: not group.isnull().any())\n",
    "\n",
    "# Extract the list of districts with full data\n",
    "districts_with_full_data_list = districts_with_full_data[districts_with_full_data].index.tolist()\n",
    "\n",
    "# Print or use the list as needed\n",
    "print(\"Districts with full data:\", districts_with_full_data_list)\n",
    "print(len(districts_with_full_data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd117537",
   "metadata": {},
   "source": [
    "### Weather Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aad1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cop_all = xr.open_mfdataset(paths='../data/raw_data/*.nc', combine='by_coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3504580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mean of latitude, longitude dims as they only deviate marginally\n",
    "cop_all.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30446da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cop_all_centralized = cop_all.mean(dim=['latitude', 'longitude'])\n",
    "\n",
    "cop_all_centralized.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_append = canola_dist1['Canola'].tolist()\n",
    "\n",
    "dist1_df = cop_all_centralized.to_dataframe()\n",
    "\n",
    "years = dist1_df.index.year\n",
    "dist1_df['Canola'] = [column_to_append[year - 1971] for year in years]\n",
    "\n",
    "dist1_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9a2e0",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "canola_dist1 = canola_filtered[canola_filtered['RM'] == 1]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(canola_dist1['Canola'], label=f'Canola in district 1')\n",
    "plt.title('Canola in District 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb611c1d",
   "metadata": {},
   "source": [
    "### Differencing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad01c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing Orders (confirms that d is likely 0)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "ax1.plot(canola_dist1.Canola); ax1.set_title('Original Series'); ax1.axes.xaxis.set_visible(False)\n",
    "# 1st Differencing\n",
    "ax2.plot(canola_dist1.Canola.diff()); ax2.set_title('1st Order Differencing'); ax2.axes.xaxis.set_visible(False)\n",
    "# 2nd Differencing\n",
    "ax3.plot(canola_dist1.Canola.diff().diff()); ax3.set_title('2nd Order Differencing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8770f4",
   "metadata": {},
   "source": [
    "### Stationarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and trainingsdata \n",
    "\n",
    "test_set = canola_dist1.iloc[-10:]\n",
    "training_set = canola_dist1.iloc[:-10]\n",
    "\n",
    "#check for stationarity with Augmented Dickey-Fuller (ADF) test \n",
    "\n",
    "#in the whole dataset\n",
    "result = adfuller(canola_dist1['Canola'])\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "\n",
    "#in the trainingset\n",
    "result = adfuller(training_set['Canola'])\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29b379",
   "metadata": {},
   "source": [
    "### Detrending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbc0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "canola_dist1.index = canola_dist1.index.to_period('A')\n",
    "\n",
    "#change frequency \n",
    "frequency = canola_dist1.index.freq\n",
    "\n",
    "print(frequency)\n",
    "\n",
    "# linear detrending\n",
    "forecaster = PolynomialTrendForecaster(degree=2)\n",
    "transformer = Detrender(forecaster=forecaster)\n",
    "yt = transformer.fit_transform(canola_dist1['Canola'])\n",
    "\n",
    "\n",
    "forecaster = PolynomialTrendForecaster(degree=2)\n",
    "fh_ins = -np.arange(len(canola_dist1['Canola'])) \n",
    "y_pred = forecaster.fit(canola_dist1['Canola']).predict(fh=fh_ins)\n",
    "\n",
    "plot_series(canola_dist1['Canola'], y_pred, yt, labels=[\"y_train\", \"fitted quadratic trend\", \"residuals\"]);\n",
    "\n",
    "residuals = yt\n",
    "\n",
    "#ADF \n",
    "result = adfuller(residuals)\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09bff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add detrended time series to dataframe \n",
    "canola_dist1.loc[:,'Canola_detrend'] = yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d6727",
   "metadata": {},
   "source": [
    "# Feature Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b4dc2",
   "metadata": {},
   "source": [
    "### Average Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa31284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average temperature annual\n",
    "\n",
    "dist1_df_annual = dist1_df.resample('A').mean()\n",
    "dist1_df_annual.head()\n",
    "\n",
    "column_to_append = dist1_df_annual['t2m'].tolist()\n",
    "canola_dist1.loc[:,'average_temp_in_year'] = column_to_append\n",
    "\n",
    "canola_dist1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average temperature in one month \n",
    "\n",
    "for month in range(4,11):\n",
    "    \n",
    "    dist1_df_month = dist1_df.resample('MS').mean()\n",
    "    month_data = dist1_df_month[dist1_df_month.index.month == month]\n",
    "\n",
    "    column_to_append = month_data['t2m'].tolist()\n",
    "    canola_dist1.loc[:, f'average_temp_in_{month}'] = column_to_append\n",
    "\n",
    "canola_dist1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82764ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a46ad8",
   "metadata": {},
   "source": [
    "### Number of hot days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hot days in one year \n",
    "dist1_df_hot = dist1_df \n",
    "\n",
    "# add extra columns containing the years and the months\n",
    "dist1_df_hot['year'] = dist1_df_hot.index.year\n",
    "dist1_df_hot['month'] = dist1_df_hot.index.month\n",
    "dist1_df['day'] = dist1_df_hot.index.day\n",
    "\n",
    "# get variables year, month and canola from old data frame \n",
    "daily_df = dist1_df.resample('D').first()\n",
    "#print(len(daily_df))\n",
    "daily_df = daily_df[[\"Canola\",\"year\",\"month\"]]\n",
    "\n",
    "# Resample the data to daily frequency and get the maximum temperature for each day\n",
    "daily_max_temperature = dist1_df_hot['t2m'].resample('D').max()\n",
    "\n",
    "# add max temp per day to data frame\n",
    "daily_df['max_temp'] = daily_max_temperature\n",
    "print(len(daily_df))\n",
    "#print(daily_df[210:230])\n",
    "\n",
    "# count hot days per year \n",
    "hot_days_by_year = daily_df[daily_df[\"max_temp\"] > 303].groupby('year').size()\n",
    "\n",
    "hot_days_by_year = hot_days_by_year.reindex(range(dist1_df_hot['year'].min(), dist1_df_hot['year'].max() + 1), fill_value=0)\n",
    "\n",
    "#hot_days_by_year.plot()\n",
    "#plt.show()\n",
    "\n",
    "#append hot da\n",
    "column_to_append = hot_days_by_year.tolist()\n",
    "canola_dist1.loc[:,'hot_days_in_year'] = column_to_append\n",
    "\n",
    "# get number of hot days per month from may til august\n",
    "\n",
    "for month in range(5, 9):\n",
    "    # Filter data for the current month\n",
    "    month_data = daily_df[daily_df['month'] == month]\n",
    "\n",
    "    # hot days per year in the current month\n",
    "    hot_days_by_month = month_data[month_data[\"max_temp\"] > 303].groupby('year').size()\n",
    "\n",
    "    # Reindex to include all years and fill NaN values with 0\n",
    "    hot_days_by_month = hot_days_by_month.reindex(range(dist1_df_hot['year'].min(), dist1_df_hot['year'].max() + 1), fill_value=0)\n",
    "\n",
    "    \n",
    "    # append column to dataframe  \n",
    "    column_to_append = hot_days_by_month.tolist()\n",
    "    canola_dist1.loc[:,f'hot_days_in_{month}'] = column_to_append\n",
    "    \n",
    "    #plot \n",
    "    #hot_days_in_august_by_year.plot()\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "#print(canola_dist1.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c27cc1",
   "metadata": {},
   "source": [
    "### Days without rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample and sum out every day\n",
    "dist1_df_perci = dist1_df.resample('D').sum()\n",
    "\n",
    "print(dist1_df_perci)\n",
    "\n",
    "# problem: resample tries to apply the method to every day including days from noverber-march, fills it with nan. \n",
    "# The sum() of only nans is 0. In the data are more 0, so deleting all zeros kicks out reasonable oberservations as well\n",
    "# sum(skipna=False) does not work with resample()\n",
    "\n",
    "# use data frame without zero to calculate the 5% quantile (only!)\n",
    "dist1_df_perci_wo0 = dist1_df_perci[dist1_df_perci['tp'] != 0]\n",
    "\n",
    "#does it make sense to consider the overall quantile for all month? \n",
    "\n",
    "#calculate quantil \n",
    "quantile_5 = dist1_df_perci_wo0['tp'].quantile(0.05)\n",
    "print(\"5% Quantile for 'tp':\", quantile_5)\n",
    "\n",
    "\n",
    "daily_df['sum_percipitation'] = dist1_df_perci['tp']\n",
    "\n",
    "days_without_rain_year = daily_df[daily_df[\"sum_percipitation\"] <= quantile_5].groupby('year').size()\n",
    "\n",
    "# #append hot da\n",
    "column_to_append = days_without_rain_year.tolist()\n",
    "canola_dist1.loc[:,'days_without_rain_year'] = column_to_append\n",
    "\n",
    "#canola_dist1.columns\n",
    "\n",
    "### days without rain per month \n",
    "\n",
    "for month in range(4, 11):\n",
    "    # Filter data for the current month\n",
    "    month_data = daily_df[daily_df['month'] == month]\n",
    "\n",
    "    # hot days per year in the current month\n",
    "    days_without_rain_month = month_data[month_data[\"sum_percipitation\"] < quantile_5].groupby('year').size()\n",
    "\n",
    "    # Reindex to include all years and fill NaN values with 0\n",
    "    days_without_rain_month = days_without_rain_month.reindex(range(dist1_df_hot['year'].min(), dist1_df_hot['year'].max() + 1), fill_value=0)\n",
    "\n",
    "    \n",
    "    # append column to dataframe  \n",
    "    column_to_append = days_without_rain_month.tolist()\n",
    "    canola_dist1.loc[:,f'days_without_rain_{month}'] = column_to_append\n",
    "    \n",
    "    #plot \n",
    "    #hot_days_in_august_by_year.plot()\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "canola_dist1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccecff10",
   "metadata": {},
   "source": [
    "### Precipitation in one year/month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#percipitation in one year \n",
    "dist1_df_precipitation = dist1_df.resample('A').sum()\n",
    "dist1_df_precipitation.head()\n",
    "\n",
    "column_to_append = dist1_df_precipitation['tp'].tolist()\n",
    "canola_dist1.loc[:,'precipitation_in_year'] = column_to_append\n",
    "\n",
    "#percipitation in one month in one year\n",
    "\n",
    "for month in range(4,11):\n",
    "    \n",
    "    dist1_df_month = dist1_df.resample('MS').sum()\n",
    "    month_data = dist1_df_month[dist1_df_month.index.month == month]\n",
    "    \n",
    "    column_to_append = month_data['tp'].tolist()\n",
    "    canola_dist1.loc[:,f'precipitation_in_{month}'] = column_to_append\n",
    "\n",
    "canola_dist1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ccd6e",
   "metadata": {},
   "source": [
    "### Linear Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "canola_lr = canola_dist1.iloc[:, 2:]\n",
    "\n",
    "canola_lr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression using all covariates \n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X = canola_lr.iloc[:, 1:] \n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "# multicollianrity\n",
    "\n",
    "#correlation matrix\n",
    "correlation_matrix = canola_lr.corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.show()\n",
    "\n",
    "#VIF Test \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043878c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA to tackle multicollinearity\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = canola_lr.iloc[:, 1:] \n",
    "scaler.fit(X)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X, y)\n",
    "X_pca_new = pca.transform(X)   \n",
    "\n",
    "def myplot(score,coeff,labels=None):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "\n",
    "    plt.scatter(xs ,ys, c = y) #without scaling\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.5)\n",
    "        if labels is None:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', ha = 'center', va = 'center')\n",
    "\n",
    "plt.xlabel(\"PC{}\".format(1))\n",
    "plt.ylabel(\"PC{}\".format(2))\n",
    "plt.grid()\n",
    "\n",
    "myplot(X_pca_new[:,0:2], pca.components_) \n",
    "plt.show()\n",
    "\n",
    "# pca_model = sm.OLS(y, X_pca)\n",
    "# pca_results = pca_model.fit()\n",
    "\n",
    "# print(pca_results.summary())\n",
    "\n",
    "print(sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most important features on the PCs with names and save them into a pandas df\n",
    "\n",
    "model = PCA(n_components=3).fit(X)\n",
    "X_pc = model.transform(X)\n",
    "\n",
    "# number of components\n",
    "n_pcs= model.components_.shape[0]\n",
    "\n",
    "# get the index of the most important feature on EACH component\n",
    "# LIST COMPREHENSION HERE\n",
    "most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n",
    "\n",
    "initial_feature_names = ['average_temp_in_year', 'average_temp_in_4', 'average_temp_in_5',\n",
    "       'average_temp_in_6', 'average_temp_in_7', 'average_temp_in_8',\n",
    "       'average_temp_in_9', 'average_temp_in_10', 'hot_days_in_year',\n",
    "       'hot_days_in_5', 'hot_days_in_6', 'hot_days_in_7', 'hot_days_in_8',\n",
    "       'days_without_rain_year', 'days_without_rain_4', 'days_without_rain_5',\n",
    "       'days_without_rain_6', 'days_without_rain_7', 'days_without_rain_8',\n",
    "       'days_without_rain_9', 'days_without_rain_10', 'precipitation_in_year',\n",
    "       'precipitation_in_4', 'precipitation_in_5', 'precipitation_in_6',\n",
    "       'precipitation_in_7', 'precipitation_in_8', 'precipitation_in_9',\n",
    "       'precipitation_in_10']\n",
    "\n",
    "# get the names\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "\n",
    "# LIST COMPREHENSION HERE AGAIN\n",
    "dic = {'PC{}'.format(i): most_important_names[i] for i in range(n_pcs)}\n",
    "\n",
    "# build the dataframe\n",
    "df_pca = pd.DataFrame(dic.items())\n",
    "\n",
    "print(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06249ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSCanonical, PLSRegression, CCA\n",
    "\n",
    "pls = PLSRegression(n_components=2)\n",
    "pls_reg = pls.fit(X, y)\n",
    "print(pls_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa655599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression using just average temp in month \n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X = canola_lr.iloc[:, 2:9] \n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression using all covs log-transformed; no difference \n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X = canola_lr.iloc[:, 2:9] \n",
    "\n",
    "X =  np.log1p(X)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression using just hot days in month \n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X = canola_lr.iloc[:, 10:14] \n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1086ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression using just days without rain in month \n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X = canola_lr.iloc[:, 15:22] \n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression using just percipitation in month \n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X = canola_lr.iloc[:, 23:] \n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57039830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression using yearly variables\n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X = canola_lr.loc[:, ['average_temp_in_year', 'precipitation_in_year','days_without_rain_year','hot_days_in_year']] \n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0488daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression using variables in may\n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X = canola_lr.loc[:, ['average_temp_in_5', 'precipitation_in_5','days_without_rain_5','hot_days_in_5']]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d8dd86",
   "metadata": {},
   "source": [
    "### Simple linear Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ffa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot days in july\n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X_1 = canola_lr[[\"hot_days_in_7\"]]\n",
    "\n",
    "X_1 = sm.add_constant(X_1)\n",
    "\n",
    "model = sm.OLS(y, X_1)\n",
    "results_one = model.fit()\n",
    "\n",
    "print(results_one.summary())\n",
    "\n",
    "plt.scatter(canola_lr[[\"hot_days_in_7\"]], canola_lr[[\"Canola_detrend\"]], label='Outliers')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(canola_lr[[\"hot_days_in_7\"]], results_one.predict(), color='blue', label='Regression line complete')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Hot days in july')\n",
    "plt.ylabel('Canola yield')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()\n",
    "\n",
    "# check for outliners:\n",
    "df_july = canola_lr.iloc[:, [0,12]]\n",
    "\n",
    "#print(df_july)\n",
    "\n",
    "#the utliers are 2017 and 2021\n",
    "\n",
    "years_to_remove = ['2017', '2021']\n",
    "\n",
    "# Remove specific years from the DataFrame\n",
    "df_july = df_july.drop(years_to_remove, axis=0)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "#print(df_july)\n",
    "\n",
    "# lr with removed outliers \n",
    "\n",
    "y = df_july.iloc[:, 0] \n",
    "X_mod = df_july.iloc[:,1]\n",
    "\n",
    "X_mod = sm.add_constant(X_mod)\n",
    "\n",
    "model = sm.OLS(y, X_mod)\n",
    "results_one = model.fit()\n",
    "\n",
    "print(results_one.summary())\n",
    "\n",
    "plt.scatter(df_july[[\"hot_days_in_7\"]], df_july[[\"Canola_detrend\"]], label='Data points')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(df_july[[\"hot_days_in_7\"]], results_one.predict(), color='red', label='Regression line adjusted')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Hot days in july')\n",
    "plt.ylabel('Canola yield')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d39901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot days in year\n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X_1 = canola_lr[[\"hot_days_in_year\"]]\n",
    "\n",
    "X_1 = sm.add_constant(X_1)\n",
    "\n",
    "model = sm.OLS(y, X_1)\n",
    "results_one = model.fit()\n",
    "\n",
    "print(results_one.summary())\n",
    "\n",
    "plt.scatter(canola_lr[[\"hot_days_in_year\"]], canola_lr[[\"Canola_detrend\"]], label='Data points')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(canola_lr[[\"hot_days_in_year\"]], results_one.predict(), color='red', label='Regression line')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Hot days per year')\n",
    "plt.ylabel('Canola yield')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17465fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average temp in july \n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X_1 = canola_lr[[\"average_temp_in_8\"]]\n",
    "\n",
    "X_1 = sm.add_constant(X_1)\n",
    "\n",
    "model = sm.OLS(y, X_1)\n",
    "results_one = model.fit()\n",
    "\n",
    "print(results_one.summary())\n",
    "\n",
    "plt.scatter(canola_lr[[\"average_temp_in_8\"]], canola_lr[[\"Canola_detrend\"]], label='Data points')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(canola_lr[[\"average_temp_in_8\"]], results_one.predict(), color='red', label='Regression line')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Average temp in july')\n",
    "plt.ylabel('Canola yield')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Ordinal scale? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7977067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average temp in year\n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X_1 = canola_lr[[\"average_temp_in_year\"]]\n",
    "\n",
    "X_1 = sm.add_constant(X_1)\n",
    "\n",
    "model = sm.OLS(y, X_1)\n",
    "results_one = model.fit()\n",
    "residuals = results_one.resid\n",
    "fitted_values = results_one.fittedvalues\n",
    "\n",
    "print(results_one.summary())\n",
    "\n",
    "plt.scatter(canola_lr[[\"average_temp_in_year\"]], canola_lr[[\"Canola_detrend\"]], label='Data points')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(canola_lr[[\"average_temp_in_year\"]], results_one.predict(), color='red', label='Regression line')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Average temp in year')\n",
    "plt.ylabel('Canola yield')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37390450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(residuals, line='45', fit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fitted_values, residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.title(\"Residuals vs Fitted Values\")\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd02dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percipitation in july\n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X_1 = canola_lr[[\"precipitation_in_7\"]]\n",
    "\n",
    "X_1 = sm.add_constant(X_1)\n",
    "\n",
    "model = sm.OLS(y, X_1)\n",
    "results_one = model.fit()\n",
    "\n",
    "print(results_one.summary())\n",
    "\n",
    "plt.scatter(canola_lr[[\"precipitation_in_7\"]], canola_lr[[\"Canola_detrend\"]], label='Data points')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(canola_lr[[\"precipitation_in_7\"]], results_one.predict(), color='red', label='Regression line')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Percipitation in july')\n",
    "plt.ylabel('Canola yield')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(canola_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days without rain \n",
    "\n",
    "y = canola_lr.iloc[:, 0] \n",
    "X_1 = canola_lr[[\"days_without_rain_5\"]]\n",
    "\n",
    "X_1 = sm.add_constant(X_1)\n",
    "\n",
    "model = sm.OLS(y, X_1)\n",
    "results_one = model.fit()\n",
    "\n",
    "print(results_one.summary())\n",
    "\n",
    "plt.scatter(canola_lr[[\"days_without_rain_5\"]], canola_lr[[\"Canola_detrend\"]], label='Data points')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(canola_lr[[\"days_without_rain_5\"]], results_one.predict(), color='red', label='Regression line')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('days without rain in 5')\n",
    "plt.ylabel('Canola yield')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#non are significant "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c4b95",
   "metadata": {},
   "source": [
    "### ARIMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "plot_acf(training_set['Canola'], lags=20, ax=ax1) # p = 1\n",
    "plot_pacf(training_set['Canola'], lags=20, ax=ax2) # q = 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdbd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model \n",
    "\n",
    "p, d, q = (0, 1, 1)\n",
    "model = ARIMA(training_set['Canola'], order=(p, d, q), freq = \"AS-JAN\")\n",
    "results = model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(results.summary())\n",
    "\n",
    "# Plot diagnostics\n",
    "results.plot_diagnostics(figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f09e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecastingt \n",
    "\n",
    "forecast_steps = 10 \n",
    "forecast = results.get_forecast(steps=forecast_steps)\n",
    "forecast_ci = forecast.conf_int()\n",
    "\n",
    "forecast_start_date = training_set.index[-1] + pd.DateOffset(years=1)\n",
    "forecast_end_date = forecast.predicted_mean.index[-1]\n",
    "full_index = pd.date_range(start=training_set.index[0], end=forecast_end_date, freq='AS-JAN')\n",
    "forecast.predicted_mean = forecast.predicted_mean.reindex(full_index, fill_value=None)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_set['Canola'], label='Observed')\n",
    "plt.plot(test_set.index, test_set['Canola'], label='Test Set (Observed)', color='green')\n",
    "plt.plot(forecast.predicted_mean, color='red', label='Forecast')\n",
    "plt.fill_between(forecast_ci.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='red', alpha=0.2)\n",
    "plt.title('ARIMA Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5949be1",
   "metadata": {},
   "source": [
    "### Exponential Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_star = None\n",
    "best_mse = None\n",
    "dat = canola_dist1.iloc[:, :].values.astype('float32')\n",
    "mean_results_for_all_possible_alpha_values = np.zeros(9)\n",
    "for alpha in range(0, 9):\n",
    "    pt = np.mean(dat[:, 0][0:5])\n",
    "    mean_for_alpha = np.zeros(len(dat))\n",
    "    mean_for_alpha[0] = np.power(dat[0][0] - pt, 2)\n",
    "    for i in range(1, len(dat)):\n",
    "        pt = pt + ((alpha + 1) * 0.1) * (dat[i - 1][0] - pt)\n",
    "        mean_for_alpha[i] = np.power(dat[i][0] - pt, 2)\n",
    "    mean_results_for_all_possible_alpha_values[alpha] = np.mean(mean_for_alpha)\n",
    "alpha_star = (np.argmin(mean_results_for_all_possible_alpha_values) + 1) * 0.1\n",
    "best_mse = np.min(mean_results_for_all_possible_alpha_values)\n",
    "print(\"Best MSE = %s\" % best_mse)\n",
    "print(\"Optimal alpha = %s\" % alpha_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = SimpleExpSmoothing(training_set['Canola'])\n",
    "model3_fit = model3.fit(smoothing_level=0.1,optimized=False)\n",
    "model3_fit.params\n",
    "y_hat_ses = test_set.copy()\n",
    "y_hat_ses['ses_forecast'] = model3_fit.forecast(len(test_set))\n",
    "\n",
    "print(y_hat_ses['ses_forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ed653",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,7))\n",
    "plt.grid()\n",
    "plt.plot(training_set['Canola'], label='Train')\n",
    "plt.plot(test_set['Canola'], label='Test')\n",
    "plt.plot(y_hat_ses['ses_forecast'], label='Forecast')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Simple Exponential Smoothing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af62869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' is your DataFrame containing the variables\n",
    "# 'Canola_detrend', 'average_temp_in_year', 'precipitation_in_year', etc.\n",
    "\n",
    "# Extract relevant features and target variable\n",
    "features = canola_lr.drop('Canola_detrend', axis=1).values\n",
    "target = canola_lr['Canola_detrend'].values.reshape(-1, 1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.Tensor(X_train).unsqueeze(2)  # Add an extra dimension for the input sequence\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "\n",
    "X_test_tensor = torch.Tensor(X_test).unsqueeze(2)\n",
    "y_test_tensor = torch.Tensor(y_test)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = X_train_tensor.shape[2]\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30 # still way too little\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}') # print loss every 5th epoch\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "\n",
    "print(f'Test Loss: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://services9.arcgis.com/WJsMXAAF3vSdDYis/arcgis/rest/services/SaskAdmin_2016_rural_municipality/FeatureServer/0\"\n",
    "response = requests.get(url, params={\"param1\": \"value1\", \"param2\": \"value2\"}, headers={\"Authorization\": \"Bearer YOUR_TOKEN\"})\n",
    "\n",
    "# Check the status code\n",
    "# if response.status_code == 200:\n",
    "#     # The request was successful\n",
    "#     data = response.json()\n",
    "# else:\n",
    "#     # Handle the error\n",
    "#     print(f\"Error: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
